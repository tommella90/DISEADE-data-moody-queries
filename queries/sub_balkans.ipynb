{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CONVERT FILES WITH DUCK_DB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import duckdb\n",
    "import os\n",
    "import time\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "OUTPUT_PATH = r\"..\\\\data_processed\\\\balkans\\\\\" "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def time_it(func):\n",
    "    \"\"\"Decorator to measure the execution time of a function.\"\"\"\n",
    "    def wrapper(*args, **kwargs):\n",
    "        start_time = time.time()  \n",
    "        result = func(*args, **kwargs) \n",
    "        end_time = time.time() \n",
    "        elapsed_time = end_time - start_time  \n",
    "        print(f\"Execution time: {elapsed_time:.4f} seconds\")  \n",
    "        return result\n",
    "    return wrapper"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Ownership history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "balkans = [\n",
    "    \"BA\", \"XK\", \"MK\", \"CS\", \"AL\"\n",
    "]\n",
    "##"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "TEMP_TABLE_FIRMOGRAPHICS = \"..\\\\data_processed\\\\firmographics_processed\" \n",
    "TEMP_TABLE_KEY_FINANCIALS_DETAILED = \"..\\\\data_processed\\\\key_financials_detailed_processed\"\n",
    "\n",
    "\n",
    "def get_ownership_data(year, country, path=None):\n",
    "    print(f\"{country} - {year}...\")\n",
    "\n",
    "    COUNTRY_KEY_FINANCIALS = TEMP_TABLE_KEY_FINANCIALS_DETAILED + f\"\\\\key_financials_detailed_{country}.parquet\"\n",
    "    COUNTRY_FIRMOGRAPHICS = TEMP_TABLE_FIRMOGRAPHICS + f\"\\\\firmographics_{country}.parquet\" \n",
    "\n",
    "    query = f\"\"\"\n",
    "        SELECT\n",
    "            main.subsidiary_bvd_id,\n",
    "            main.guo_25,\n",
    "            {year} AS year,\n",
    "\n",
    "            firmographics_sub.nuts2 AS subsidiary_nuts2,\n",
    "            firmographics_sub.nace_rev_2_core_code_4_digits_ AS subsidiary_nace4,\n",
    "            firmographics_guo.nuts2 AS guo_nuts2,\n",
    "            firmographics_guo.nace_rev_2_core_code_4_digits_ AS guo_nace4,\n",
    "            firmographics_guo.type_of_entity AS guo_type_of_entity,\n",
    "            firmographics_guo.status AS guo_status,\n",
    "            \n",
    "            key_financials_detailed.operating_revenue_turnover_,\n",
    "            key_financials_detailed.number_of_employees,\n",
    "            key_financials_detailed.costs_of_goods_sold,\n",
    "            key_financials_detailed.material_costs,\n",
    "            key_financials_detailed.added_value\n",
    "        FROM \n",
    "            '{path}' AS main\n",
    "\n",
    "        LEFT JOIN \n",
    "            '{COUNTRY_KEY_FINANCIALS}' AS key_financials_detailed\n",
    "        ON \n",
    "            main.subsidiary_bvd_id = key_financials_detailed.bvd_id_number\n",
    "        AND\n",
    "            key_financials_detailed.year = {year}\n",
    "\n",
    "        LEFT JOIN \n",
    "            '{COUNTRY_FIRMOGRAPHICS}' AS firmographics_sub\n",
    "        ON \n",
    "            main.subsidiary_bvd_id = firmographics_sub.bvd_id_number\n",
    "\n",
    "        LEFT JOIN \n",
    "            '{COUNTRY_FIRMOGRAPHICS}' AS firmographics_guo\n",
    "        ON \n",
    "            main.guo_25 = firmographics_guo.bvd_id_number\n",
    "\n",
    "        WHERE \n",
    "            main.\"type_of_relation\" = 'GUO 25'\n",
    "        AND \n",
    "            main.\"subsidiary_bvd_id\" LIKE '{country}%'\n",
    "\n",
    "    \"\"\"\n",
    "\n",
    "    conn = duckdb.connect()\n",
    "    df = conn.execute(query).fetchdf()\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# path = \"..\\\\data_raw\\\\ownership_history\\\\links_2007\\\\*.parquet\"\n",
    "country = \"AL\"\n",
    "year = \"2019\"\n",
    "path = \"..\\\\data_raw\\\\ownership_history\\\\links_2019\\\\*.parquet\"\n",
    "\n",
    "df_al = get_ownership_data(\n",
    "    path=path,\n",
    "    year=year,\n",
    "    country=country,\n",
    ")\n",
    "df_al"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "@time_it\n",
    "def fetch_and_convert_to_excel(year, country, path, output_path):\n",
    "    df = get_ownership_data(year, country, path)\n",
    "    os.makedirs(output_path, exist_ok=True)\n",
    "\n",
    "    # Split the DataFrame into 5 chunks\n",
    "    chunks = 5\n",
    "    indices = np.array_split(df.index, chunks)\n",
    "    slices = [df.iloc[idx] for idx in indices]\n",
    "\n",
    "    for i, s in enumerate(slices):\n",
    "        s.to_csv(f\"{output_path}\\\\{country}_{year}_chunk_{i+1}.csv\", index=False)\n",
    "    \n",
    "        print(f\"Data for {country} - {year} - slice_{i+1} has been converted.\")\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "import json\n",
    "\n",
    "errors = {}\n",
    "OUTPUT_PATH = r\"..\\\\data_processed\\\\balkans\\\\\" \n",
    "\n",
    "total_start = time.time()\n",
    "start_time = time.time()\n",
    "\n",
    "\n",
    "for country in balkans:\n",
    "    for year in range(2007, 2023):\n",
    "        year = str(year)\n",
    "        try:\n",
    "            path = f\"..\\\\data_raw\\\\ownership_history\\\\links_{year}\\\\*.parquet\"\n",
    "            fetch_and_convert_to_excel(year, country, path, OUTPUT_PATH)  \n",
    "            end_time = time.time()\n",
    "            duration = end_time - start_time\n",
    "            print(f\"Data for {country} - {year} has been converted to excel in {duration:.2f} seconds.\")\n",
    "        except Exception as e:\n",
    "            errors[f\"{country} - {year}\"] = str(e)\n",
    "            print(f\"Error {country} - {year}\")\n",
    "            continue\n",
    "\n",
    "\n",
    "end_time = time.time()\n",
    "duration = end_time - start_time\n",
    "total_end = time.time()\n",
    "total_duration = total_end - total_start\n",
    "print(f\"Total execution time: {total_duration:.2f} seconds.\")\n",
    "\n",
    "with open(\"errors\\\\errors_balkans.json\", \"w\") as f:\n",
    "    json.dump(errors, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# open errors\n",
    "import json \n",
    "\n",
    "with open(\"errors/errors_balkans.json\", \"r\") as f:\n",
    "    errors = json.load(f)\n",
    "\n",
    "errors"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## zip the files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Archive created at z:\\dati_moody\\zipped_files\\balkans_zipped.zip\n"
     ]
    }
   ],
   "source": [
    "from utils import zip\n",
    "OUTPUT_PATH = r\"..\\\\data_processed\\\\balkans\\\\\" \n",
    "zipper = zip.FileZipper(OUTPUT_PATH) \n",
    "zipper.zip_folder(\"balkans.zip\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['.git',\n",
       " '.gitignore',\n",
       " '.python-version',\n",
       " '.venv',\n",
       " 'constants.py',\n",
       " 'data_processed',\n",
       " 'data_raw',\n",
       " 'dati_moody.egg-info',\n",
       " 'pyproject.toml',\n",
       " 'queries',\n",
       " 'README.md',\n",
       " 'setup.py',\n",
       " 'utils',\n",
       " 'uv.lock',\n",
       " 'zipped_files',\n",
       " '__pycache__']"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "os.listdir(\"..\\\\zipped_files\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: '..\\\\data_processed\\\\balkans\\\\balkans.csv'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[1], line 11\u001b[0m\n\u001b[0;32m      8\u001b[0m output_csv_gz \u001b[38;5;241m=\u001b[39m os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mjoin(INPUT_PATH, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mbalkans.csv.gz\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m     10\u001b[0m \u001b[38;5;66;03m# Compress the CSV file using gzip\u001b[39;00m\n\u001b[1;32m---> 11\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28;43mopen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43minput_csv\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mrb\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mas\u001b[39;00m f_in:\n\u001b[0;32m     12\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m gzip\u001b[38;5;241m.\u001b[39mopen(output_csv_gz, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mwb\u001b[39m\u001b[38;5;124m'\u001b[39m) \u001b[38;5;28;01mas\u001b[39;00m f_out:\n\u001b[0;32m     13\u001b[0m         shutil\u001b[38;5;241m.\u001b[39mcopyfileobj(f_in, f_out)\n",
      "File \u001b[1;32mz:\\dati_moody\\.venv\\Lib\\site-packages\\IPython\\core\\interactiveshell.py:324\u001b[0m, in \u001b[0;36m_modified_open\u001b[1;34m(file, *args, **kwargs)\u001b[0m\n\u001b[0;32m    317\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m file \u001b[38;5;129;01min\u001b[39;00m {\u001b[38;5;241m0\u001b[39m, \u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m2\u001b[39m}:\n\u001b[0;32m    318\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[0;32m    319\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mIPython won\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mt let you open fd=\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfile\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m by default \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    320\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mas it is likely to crash IPython. If you know what you are doing, \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    321\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124myou can use builtins\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m open.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    322\u001b[0m     )\n\u001b[1;32m--> 324\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mio_open\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfile\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[1;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '..\\\\data_processed\\\\balkans\\\\balkans.csv'"
     ]
    }
   ],
   "source": [
    "import gzip\n",
    "import shutil\n",
    "import os\n",
    "\n",
    "# Define the paths\n",
    "INPUT_PATH = \"..\\\\data_processed\\\\balkans\"\n",
    "OUTPUT_PATH = \"..\\\\zipped_files\"\n",
    "\n",
    "\n",
    "input_csv = os.path.join(INPUT_PATH, \"balkans.csv\")\n",
    "output_csv_gz = os.path.join(INPUT_PATH, \"balkans.csv.gz\")\n",
    "\n",
    "# Compress the CSV file using gzip\n",
    "with open(input_csv, 'rb') as f_in:\n",
    "    with gzip.open(output_csv_gz, 'wb') as f_out:\n",
    "        shutil.copyfileobj(f_in, f_out)\n",
    "\n",
    "print(f\"Compressed {input_csv} to {output_csv_gz}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
